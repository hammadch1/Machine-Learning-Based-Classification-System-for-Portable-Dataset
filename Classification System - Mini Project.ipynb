{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox \n",
    "import time\n",
    "from tkinter.ttk import *\n",
    "from tkinter import *\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from collections import deque \n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Bayes_Classifier(featureList, X, y):\n",
    "    global m_estimate_flag\n",
    "    print('m estimate', m_estimate_flag)\n",
    "    def TrainingSamplesOfClass(classID, out_class):\n",
    "        # count classID and return\n",
    "        temp=0\n",
    "        for i in out_class:\n",
    "            if i==classID:\n",
    "                temp= temp+1\n",
    "        return temp\n",
    "    \n",
    "    def calculatePriorProbability(count, length):\n",
    "        return count/length\n",
    "\n",
    "    classes = np.unique(y.values)\n",
    "    target = dict()\n",
    "    for label in range(len(classes)):\n",
    "        target[classes[label]]=label;\n",
    "    \"\"\"\n",
    "    key: classes[i], value: target[classes[i]]\n",
    "    Iris-setosa: 0\n",
    "    \"\"\"\n",
    "    # each class counting/total in total samples\n",
    "    count_class = list()\n",
    "    for i in range(len(classes)):\n",
    "        count_class.append(TrainingSamplesOfClass(classes[i],y.values))\n",
    "\n",
    "    # CALCULATING PRIOR PROBABILITIES\n",
    "    prior_class = list()\n",
    "    for i in range(len(classes)):\n",
    "        prior_class.append(calculatePriorProbability(count_class[i],len(y.values)))\n",
    "\n",
    "    def featureCountGivenThatLabel(f_val_x, features, classID, out_class):\n",
    "        count=0\n",
    "        for fx, o_class in zip(features, out_class):\n",
    "                if fx == f_val_x and o_class == classID:\n",
    "                    count = count+1\n",
    "        return count\n",
    "\n",
    "    def calculateProbability(class_i, like_class):\n",
    "        sum_of_likelihoods = 0\n",
    "        for lik in like_class:\n",
    "            sum_of_likelihoods = sum_of_likelihoods + lik\n",
    "        import sys\n",
    "        if sum_of_likelihoods == 0:\n",
    "            print('No existence found for any of your entered feature so use m-estimate')\n",
    "            global root\n",
    "            root.destroy()\n",
    "            sys.exit()\n",
    "        return like_class[target[class_i]]/sum_of_likelihoods\n",
    "\n",
    "    def calculateLikelihood(condProbility_featureList_Class, prior_Class):\n",
    "        product =1;\n",
    "        for p in condProbility_featureList_Class:\n",
    "            product = product*p;\n",
    "        return product * prior_Class\n",
    "\n",
    "    def m_estimate(a, b, p, m):\n",
    "        return (a + m*p)/(b + m)\n",
    "\n",
    "    def NBC():\n",
    "        no_of_features = len(featureList)\n",
    "\n",
    "        # CALCULATING CONDITIONAL PROBABILITIES\n",
    "        # for N number of Classes\n",
    "        conditional_counts = list()\n",
    "        conditional_probabilities = list()\n",
    "\n",
    "        for class_i in range(len(classes)):\n",
    "            count_list = []\n",
    "            prob_list = []\n",
    "            for feature in range(len(featureList)):\n",
    "                count_list.append(featureCountGivenThatLabel(featureList[feature], X[X.columns[feature]].values, \n",
    "                                                             classes[class_i], y.values))\n",
    "                prob_list.append(count_list[feature]/count_class[class_i])\n",
    "                if m_estimate_flag == 1 and prob_list[-1] == 0:\n",
    "                    t = len(np.unique(X[X.columns[feature]].values))\n",
    "                    prob_list[-1] = m_estimate(count_list[-1], count_class[class_i], 1/t, \n",
    "                                               len(X[X.columns[feature]].values))\n",
    "            conditional_counts.append(count_list)\n",
    "            conditional_probabilities.append(prob_list)\n",
    "\n",
    "        # CALCULATING LIKELIHOODS\n",
    "        like_class = list()\n",
    "        for i in range(len(classes)):\n",
    "            like_class.append(calculateLikelihood(conditional_probabilities[i] , prior_class[i]))\n",
    "\n",
    "        # CALCULATING POSTERIOR PROBABILITIES\n",
    "        prob_class = []\n",
    "        maxim=0\n",
    "\n",
    "        for i in range(len(classes)):\n",
    "            lst = []\n",
    "            lst.append(calculateProbability(classes[i], like_class))\n",
    "            if maxim < lst[-1]:\n",
    "                maxim = lst[-1]\n",
    "            lst.append(classes[i])\n",
    "            prob_class.append(lst)\n",
    "\n",
    "        prob_class.sort(key=lambda x:float(x[0]), reverse=True)\n",
    "        predicted_class = 'Class_i'\n",
    "        GUI_msg = str()\n",
    "        for i in range(len(classes)):\n",
    "            #GUI_msg = GUI_msg + 'Predicted Outcome using NBC is ' + str(prob_class[i][1]) + ' with probability ' + str(prob_class[i][0]*100) + \"\\n\"\n",
    "            if i==0:\n",
    "                #print('Predicted Outcome using NBC is',prob_class[i][1],'with probability', prob_class[i][0]*100)#maxim*100)\n",
    "                GUI_msg = 'Predicted Class using Naive Bayes Classifier is ' + str(prob_class[i][1]) + ' with probability ' + str(round(prob_class[i][0]*100, 2))\n",
    "                predicted_class = prob_class[i][1]\n",
    "        return GUI_msg, predicted_class\n",
    "    return NBC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_Nearest_Neighbor(featureList, X, y):\n",
    "    global k, distance_metric_choice\n",
    "    def calcEuclidean():\n",
    "        row = list()\n",
    "        for i in range(len(X)):\n",
    "            #print(i,' : ')\n",
    "            t3 = 0\n",
    "            for j in range(len(X.iloc[0])):\n",
    "                #print('\\t',j)\n",
    "                # Take (P1-P2)^2 first\n",
    "                t1 = X.iloc[i][j] - featureList[j] # inner bracket\n",
    "                t2 = t1 * t1 # Squaring\n",
    "                t3 = t3 + t2 # Adding all values under Square Root\n",
    "\n",
    "            row.append(math.sqrt(t3)) # Each entry is distance of corresponding row in X\n",
    "            #row[i].append(Y.iloc[i])\n",
    "\n",
    "        row = pd.DataFrame(row)\n",
    "        dist = pd.concat([row, y], axis=1) # Concating Targets at the end of distance of each sample\n",
    "        # adding column name to the respective columns \n",
    "        dist.columns =['Distance', 'Target'] \n",
    "        dist.sort_values(by=['Distance'], inplace=True)  #  Sorting W.R.T Distance Values    \n",
    "        distK = dist.head(k)  #  Extracting only K number of values\n",
    "        #display(distK)\n",
    "        result = distK['Target'].mode() # Taking Target with maximum occurrences\n",
    "        print('Result :\\n',result[0]) # Displaying only 1st Output\n",
    "        #print('Result :\\n',result) # Displaying only 1st Output\n",
    "        predicted_class = 'Class_i'\n",
    "        GUI_msg = str()\n",
    "        GUI_msg = 'Predicted Class using k-Nearest Neighbors is ' + str(result[0])\n",
    "        predicted_class = str(result[0])\n",
    "        return GUI_msg, predicted_class\n",
    "\n",
    "    def calcManhattan():\n",
    "        row = list()\n",
    "        for i in range(len(X)):\n",
    "            #print(i,' : ')\n",
    "            t3 = 0\n",
    "            for j in range(len(X.iloc[0])):\n",
    "                #print('\\t',j)\n",
    "\n",
    "                t1 = X.iloc[i][j] - featureList[j] # inner bracket --> (P1-P2)^2\n",
    "                t2 = t1 * t1 # Squaring\n",
    "                t3 = t3 + t2 # Adding all values under Square Root\n",
    "            row.append(t3) # Each entry is distance of corresponding row in X\n",
    "\n",
    "        row = pd.DataFrame(row)\n",
    "        dist = pd.concat([row, y], axis=1) # Concating Targets at the end of distance of each sample\n",
    "        dist.columns =['Distance', 'Target']  # adding column name to the respective columns \n",
    "        dist.sort_values(by=['Distance'], inplace=True)  #  Sorting W.R.T Distance Values\n",
    "        distK = dist.head(k)  #  Extracting only K number of values\n",
    "        #display(distK)\n",
    "        result = distK['Target'].mode() # Taking Target with maximum occurrences\n",
    "        print('Result :\\n',result[0]) # Displaying only 1st Output\n",
    "        predicted_class = 'Class_i'\n",
    "        GUI_msg = str()\n",
    "        GUI_msg = 'Predicted Class using k-Nearest Neighbors is ' + str(result[0])\n",
    "        predicted_class = str(result[0])\n",
    "        return GUI_msg, predicted_class\n",
    "    \n",
    "    #print(distance_metric_choice, type(distance_metric_choice))\n",
    "    if distance_metric_choice == 1:  # For Manhattan Distance\n",
    "        #print('calling manhattan')\n",
    "        return calcManhattan()\n",
    "    elif distance_metric_choice == 2:  # For Euclidean Distance\n",
    "        #print('calling euclidean')\n",
    "        return calcEuclidean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decision_Tree_Classifier(featureList, X, y):\n",
    "    global max_depth\n",
    "    clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth = max_depth, \n",
    "                             random_state = 0)\n",
    "    X.to_numpy()\n",
    "    y.to_numpy()\n",
    "    clf = clf.fit(X, y)\n",
    "    \n",
    "    # Predict for 1 observation\n",
    "    featureList = np.array(featureList)\n",
    "    featureList = featureList.reshape(1, -1)\n",
    "    #print('print shape ', featureList.shape)\n",
    "    y_pred = clf.predict(featureList)\n",
    "    #print('print prediction ', y_pred)\n",
    "    predicted_class = y_pred[0]\n",
    "    GUI_msg = str()\n",
    "    GUI_msg = 'Predicted Class using Decision Tree Classifier is ' + predicted_class\n",
    "    return GUI_msg, predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES--------------------------------------------------------------------------------------------------\n",
    "classification_count = 0\n",
    "m_estimate_flag = 0\n",
    "distance_metric_choice=0\n",
    "k=0\n",
    "max_depth=0\n",
    "stack=[]\n",
    "load_dataset_count=0\n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "def rbutton(v):\n",
    "    stack.append(v.get())\n",
    "    print(v.get())\n",
    "    \n",
    "def take_input(root, X_data, y_data, chosen_algo):\n",
    "    no_of_features = len(X_data.columns)\n",
    "    label = Label(root, \n",
    "                  text = \"Enter Unseen sample in below \"+str(no_of_features)+\" entry cells and then click on \"\n",
    "                  \"Show Classification button\",\n",
    "                  font='Arial 16 bold', fg='white', bg=\"grey\").place(x=100, y=100)\n",
    "    horizontal=105\n",
    "    hori_ratio = int((900/no_of_features))\n",
    "    width_ratio = int(hori_ratio/(no_of_features**2))\n",
    "\n",
    "    for i in range(no_of_features):\n",
    "        value = i#'feature %d'%(i+1)\n",
    "        if width_ratio<10:\n",
    "            width_ratio = 10\n",
    "        t= Text(root, height=1, width=width_ratio, font='Arial '+str(width_ratio))\n",
    "        t.insert('1.0', value)\n",
    "        t.place(x=horizontal, y=150)\n",
    "        stack.append(t)\n",
    "        horizontal = horizontal + hori_ratio\n",
    "    show_classification = tk.Button(root, text='Show Classification',\n",
    "                padx=35, pady=10,\n",
    "                fg=\"white\", bg=\"grey\", command=lambda:classify(root, chosen_algo, X_data, y_data, show_classification))\n",
    "    show_classification.pack(side=tk.RIGHT)    \n",
    "\n",
    "count_wrong_k=0 \n",
    "def setting_parameters_chosen_algo(root, top1, chosen_algo, X_data, y_data):\n",
    "        \n",
    "    if chosen_algo == \"Naive Bayes Classifier\":\n",
    "        \n",
    "        Label3 = Label(top1, text=\"Do you want to use m-estimate technique:\", font='Arial 10').place(x=70, y=50)\n",
    "        var = IntVar(top1)\n",
    "        Check_Button = Checkbutton(top1, text='M-Estimate',variable=var, onvalue=1, offvalue=0,\n",
    "                                   command=lambda:rbutton(var)).place(x=120, y=70)\n",
    "        button1 = Button(top1, text = \"Submit Your Choice\", padx=20, pady=5, fg=\"white\", bg=\"grey\",\n",
    "                    command = lambda : submit_naive_parameters(root, top1, X_data, y_data)).pack(side=tk.BOTTOM)#top1.destroy)\n",
    "        def submit_naive_parameters(root, top1, X_data, y_data):\n",
    "            global m_estimate_flag\n",
    "            if len(stack) != 0:\n",
    "                m_estimate_flag = stack.pop()\n",
    "                stack.clear()\n",
    "            top1.destroy()\n",
    "            take_input(root, X_data, y_data, chosen_algo)\n",
    "        \n",
    "    elif chosen_algo == \"k-Nearest Neighbor\":\n",
    "        global distance_metric_choice\n",
    "        Label3 = Label(top1, text=\"k (1 to \"+str(len(X_data))+\"):\", font='Arial 12').place(x=100, y=40)\n",
    "        k_var = StringVar(top1)\n",
    "        entry = Entry(top1, textvariable=k_var).place(x=190, y=43)\n",
    "        Label4 = Label(top1, text=\"Distance Metric:\", font='Arial 12').place(x=100, y=70)\n",
    "        v = StringVar(top1, \"1\")\n",
    "        distance_metric_choice=1\n",
    "        rb1 = Radiobutton(top1, text = \"Manhattan\", variable = v,  \n",
    "                    value = \"1\", indicator = 0, command =lambda:rbutton(v)).place(x=220, y=70)\n",
    "        rb2 = Radiobutton(top1, text = 'Euclidean', variable = v,  \n",
    "                    value = \"2\", indicator = 0, command =lambda:rbutton(v)).place(x=300, y=70)\n",
    "        button1 = Button(top1, text = \"Submit Your Choice\", padx=20, pady=5, fg=\"white\", bg=\"grey\",\n",
    "                    command = lambda : submit_knn_parameters(root, top1, k_var.get(), X_data, y_data)).pack(side=tk.BOTTOM)#top1.destroy)\n",
    "        def submit_knn_parameters(root, top1, k_var, X_data, y_data):\n",
    "            global k\n",
    "            global distance_metric_choice, count_wrong_k\n",
    "            k = int(k_var)\n",
    " \n",
    "            if len(stack) != 0:\n",
    "                distance_metric_choice = int(stack[-1])\n",
    "            #print('distance_metric_choice in knn paramter',distance_metric_choice)\n",
    "                \n",
    "            if(k < 1 or k > len(X_data)):\n",
    "                count_wrong_k = count_wrong_k + 1\n",
    "                if count_wrong_k==1:\n",
    "                    Label3 = Label(top1, text=\"Invalid k value, try again\", font='Arial 10').place(x=100, y=95)\n",
    "            else:\n",
    "                stack.clear()\n",
    "                top1.destroy()\n",
    "                take_input(root, X_data, y_data, chosen_algo)\n",
    "            \n",
    "            \n",
    "    elif chosen_algo == \"Decision Tree\":\n",
    "        \n",
    "        Label3 = Label(top1, text=\"Max Depth:\", font='Arial 12').place(x=100, y=70)\n",
    "        maxDepth_var = StringVar(top1)\n",
    "        entry = Entry(top1, textvariable=maxDepth_var).place(x=200, y=73)\n",
    "        button1 = Button(top1, text = \"Submit Your Choice\", padx=20, pady=5, fg=\"white\", bg=\"grey\",\n",
    "                    command = lambda : submit_dtree_parameters(root, top1, maxDepth_var.get(), X_data, y_data)).pack(side=tk.BOTTOM)#top1.destroy)\n",
    "        def submit_dtree_parameters(root, top1, maxDepth_var, X_data, y_data):\n",
    "            global max_depth\n",
    "            max_depth = int(maxDepth_var)\n",
    "                \n",
    "            top1.destroy()\n",
    "            take_input(root, X_data, y_data, chosen_algo)\n",
    "\n",
    "def submit_algo(root, top1, values, X_data, y_data):\n",
    "    # clear window Toplevel 1\n",
    "    lst = top1.pack_slaves()\n",
    "    for l in lst:\n",
    "        l.destroy()\n",
    "    # list out keys and values separately\n",
    "    key_list = list(values.keys())\n",
    "    val_list = list(values.values())\n",
    "\n",
    "    # print key with val\n",
    "    if len(stack) != 0:\n",
    "        val = str(stack.pop())\n",
    "        position = val_list.index(val)\n",
    "        stack.clear()\n",
    "        chosen_algo = key_list[position]\n",
    "        label = Label(top1, text = \"Chosen Algo is \" + chosen_algo, font='Arial 12').pack()   \n",
    "        setting_parameters_chosen_algo(root, top1, chosen_algo, X_data, y_data)\n",
    "    \n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    global load_dataset_count\n",
    "    load_dataset_count = load_dataset_count + 1\n",
    "    def load_dataset_first_time():\n",
    "        csv_data=''\n",
    "        while csv_data=='':\n",
    "            csv_data = filedialog.askopenfilename(initialdir=\"/Downloads\", title=\"Choose a Dataset to to load its saved samples\",\n",
    "                                           filetypes=((\"all files\", \"*.*\"), (\"csv files\", \"*.csv\")))\n",
    "            if csv_data=='':\n",
    "                messagebox.showerror(\"ERROR\", 'Unable to find or open file ' + csv_data)\n",
    "        data = pd.read_csv(csv_data)\n",
    "        last_column = data.columns.values[len(data.columns)-1]\n",
    "        # X: features y: labels\n",
    "        X_data = data.drop(columns=last_column)\n",
    "        y_data = data[[last_column]]\n",
    "\n",
    "        #---------------------------------------------------------------------------------------------------------------\n",
    "        # Messagebox\n",
    "        messagebox.showinfo(\"Dataset Load Status\", \"Chosen Dataset has been loaded\") \n",
    "\n",
    "        # Creating widget for Algorithm choice \n",
    "        top1 = Toplevel(root)\n",
    "        top1.title(\"Algorithm Choice Selection\")\n",
    "        top1.geometry(\"400x200\")\n",
    "        v = StringVar(top1) \n",
    "\n",
    "        # Dictionary to create multiple buttons \n",
    "        values = {\"Naive Bayes Classifier\" : \"1\", \n",
    "                  \"k-Nearest Neighbor\" : \"2\", \n",
    "                  \"Decision Tree\" : \"3\"} \n",
    "        # Loop is used to create multiple Radiobuttons \n",
    "        # rather than creating each button separately \n",
    "        for (text, value) in values.items(): \n",
    "            Radiobutton(top1, text = text, variable = v,  \n",
    "                        value = value, indicator = 0, \n",
    "                        background = \"light blue\", command =lambda:rbutton(v)).pack(fill = X, ipady = 5)\n",
    "        button1 = Button(top1, text = \"Submit Your Choice\", padx=20, pady=5, fg=\"white\", bg=\"grey\",\n",
    "                        command = lambda : submit_algo(root, top1, values, X_data, y_data))#top1.destroy)     \n",
    "        button1.pack(side=tk.BOTTOM)\n",
    "        top1.mainloop() \n",
    "    def load_dataset_not_first_time():\n",
    "        # Creating widget for Algorithm choice \n",
    "        top1 = Toplevel(root)\n",
    "        top1.title(\"Dataset Reload Choice Selection\")\n",
    "        top1.geometry(\"400x200\")\n",
    "        Label3 = Label(top1, text=\"Do you want to load another dataset?\", \n",
    "                       font='Arial 14').place(x=40, y=10)\n",
    "        Label4 = Label(top1, text=\"Note: Labels should be in the last column of a csv file\", \n",
    "                       font='Arial 9').place(x=45, y=50)\n",
    "        button1 = Button(top1, text = \"Yes\", padx=20, pady=5, fg=\"white\", bg=\"grey\",\n",
    "                        command = lambda : load_dataset_first_time())\n",
    "        button1.place(x=120, y=170)\n",
    "        button2 = Button(top1, text = \"No\", padx=20, pady=5, fg=\"white\", bg=\"grey\",\n",
    "                        command = lambda : top1.destroy())\n",
    "        button2.place(x=210, y=170)\n",
    "        top1.mainloop() \n",
    "        \n",
    "    if load_dataset_count == 1:\n",
    "        load_dataset_first_time()\n",
    "    else:\n",
    "        load_dataset_not_first_time()\n",
    "\n",
    "def classify(root, chosen_algo, X_data, y_data, show_classification):\n",
    "    show_classification.destroy()\n",
    "    global load_dataset\n",
    "    #load_dataset.destroy()\n",
    "    \n",
    "    global classification_count\n",
    "    classification_count = classification_count + 1\n",
    "    def fun():        \n",
    "        featureList=[]\n",
    "        s = deque(stack)\n",
    "\n",
    "        for i in range(len(stack)):\n",
    "            si = s.popleft() \n",
    "            val = si.get(\"1.0\",\"end-1c\")\n",
    "            featureList.append(float(val))\n",
    "        print(featureList)\n",
    "        stack.clear()\n",
    "\n",
    "        if chosen_algo == \"Naive Bayes Classifier\":\n",
    "            GUI_msg, predicted_class = Naive_Bayes_Classifier(featureList, X_data, y_data)\n",
    "            result_label = Label(root, text = GUI_msg, font='Arial 18 bold', fg='white', \n",
    "                          bg=\"grey\")\n",
    "            result_label.place(x=100, y=350)\n",
    "            result_label.after(8, result_label.pack_forget())\n",
    "\n",
    "        elif chosen_algo == \"k-Nearest Neighbor\":\n",
    "            GUI_msg, predicted_class = k_Nearest_Neighbor(featureList, X_data, y_data)\n",
    "            result_label = Label(root, text = GUI_msg, font='Arial 18 bold', fg='white', \n",
    "                          bg=\"grey\")\n",
    "            result_label.place(x=100, y=350)\n",
    "            result_label.after(8, result_label.pack_forget())\n",
    "            \n",
    "        elif chosen_algo == \"Decision Tree\":\n",
    "            GUI_msg, predicted_class = Decision_Tree_Classifier(featureList, X_data, y_data)\n",
    "            result_label = Label(root, text = GUI_msg, font='Arial 18 bold', fg='white', \n",
    "                          bg=\"grey\")\n",
    "            result_label.place(x=100, y=350)\n",
    "            result_label.after(8, result_label.pack_forget())\n",
    "        #root.after(10000, lambda:root.destroy())\n",
    "    if classification_count > 1:\n",
    "        # clear window root\n",
    "        lst = root.pack_slaves()\n",
    "        for l in lst:\n",
    "            l.destroy()\n",
    "        canvas = tk.Canvas(root, height=500, width=1100, bg='grey')\n",
    "        canvas.pack()\n",
    "        \n",
    "        no_of_features = len(X_data.columns)\n",
    "        input_label = Label(root, \n",
    "                      text = \"Enter Unseen sample in below \"+str(no_of_features)+\" entry cells and then click on \"\n",
    "                      \"Show Classification button\",\n",
    "                      font='Arial 16 bold', fg='white', bg=\"grey\").place(x=100, y=100)\n",
    "        horizontal=105\n",
    "        hori_ratio = int((900/no_of_features))\n",
    "        width_ratio = int(hori_ratio/(no_of_features**2))\n",
    "\n",
    "        for i in range(no_of_features):\n",
    "            value = i#'f%d'%(i+1)\n",
    "            if width_ratio<10:\n",
    "                width_ratio = 10\n",
    "            t= Text(root, height=1, width=width_ratio, font='Arial '+str(width_ratio))\n",
    "            #t.insert('1.0', value)\n",
    "            t.place(x=horizontal, y=150)\n",
    "            stack.append(t)\n",
    "            horizontal = horizontal + hori_ratio\n",
    "\n",
    "        show_classification = tk.Button(root, text='Show Classification', padx=35, pady=10,\n",
    "                                        fg=\"white\", bg=\"grey\", command=fun)\n",
    "            \n",
    "        show_classification.pack(side=tk.RIGHT)    \n",
    "    \n",
    "    if classification_count==1:\n",
    "        fun()\n",
    "    \n",
    "root = tk.Tk()\n",
    "root.title('Classification System')\n",
    "root.iconbitmap('class.ico')\n",
    "root.resizable(False, False)\n",
    "tit = tk.Label(root, text=\"Classification System\", padx=25, pady=6, font=(\"\", 12)).pack()\n",
    "canvas = tk.Canvas(root, height=500, width=1100, bg='grey')\n",
    "canvas.pack()\n",
    "load_dataset = tk.Button(root, text='Load Dataset',\n",
    "                        padx=35, pady=10,\n",
    "                        fg=\"white\", bg=\"grey\", command=load_dataset)\n",
    "load_dataset.pack(side=tk.LEFT)\n",
    "\"\"\"show_classification = tk.Button(root, text='Show Classification',\n",
    "                        padx=35, pady=10,\n",
    "                        fg=\"white\", bg=\"grey\", command=classify)\n",
    "\n",
    "show_classification.pack(side=tk.RIGHT)\"\"\"\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
